{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQGm6JtgehIq"
      },
      "source": [
        "> Neural Network Weight Quantization Project for Harvard CS 2420: Computing at Scale (Fall 2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Setup**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "L6qgMN3_lGxg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRz6CSs4LwBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4bcf93-d148-47a2-fba5-c8637d87ad67"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 10 01:13:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0              46W / 400W |   1079MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WL6HA_Lpe8"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tracks the highest accuracy observed so far\n",
        "best_acc = 0\n",
        "\n",
        "def moving_average(a, n=100):\n",
        "    '''Helper function used for visualization'''\n",
        "    ret = torch.cumsum(torch.Tensor(a), 0)\n",
        "    ret[n:] = ret[n:] - ret[:-n]\n",
        "    return ret[n - 1:] / n\n",
        "\n",
        "def train(net, epoch, loader, criterion, optimizer, loss_tracker = [], acc_tracker = []):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        # update optimizer state\n",
        "        optimizer.step()\n",
        "        # compute average loss\n",
        "        train_loss += loss.item()\n",
        "        loss_tracker.append(loss.item())\n",
        "        loss = train_loss / (batch_idx + 1)\n",
        "        # compute accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "        # Print status\n",
        "        sys.stdout.write(f'\\rEpoch {epoch}: Train Loss: {loss:.3f}' +\n",
        "                         f'| Train Acc: {acc:.3f}')\n",
        "        sys.stdout.flush()\n",
        "    acc_tracker.append(acc)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def test(net, epoch, loader, criterion, loss_tracker = [], acc_tracker = []):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            loss_tracker.append(loss.item())\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            loss = test_loss / (batch_idx + 1)\n",
        "            acc = 100.* correct / total\n",
        "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    # Save checkpoint\n",
        "    acc = 100.*correct/total\n",
        "    acc_tracker.append(acc)\n",
        "    if acc > best_acc:\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc"
      ],
      "metadata": {
        "id": "BeYR2zLEM1BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOTGlfOG5IAi"
      },
      "source": [
        "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
        "               padding=1):\n",
        "    '''\n",
        "    A nn.Sequential layer executes its arguments in sequential order. In\n",
        "    this case, it performs Conv2d -> BatchNorm2d -> ReLU. This is a typical\n",
        "    block of layers used in Convolutional Neural Networks (CNNs). The\n",
        "    ConvNet implementation below stacks multiple instances of this three layer\n",
        "    pattern in order to achieve over 90% classification accuracy on CIFAR-10.\n",
        "    '''\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    '''\n",
        "    A 9 layer CNN using the conv_block function above. Again, we use a\n",
        "    nn.Sequential layer to build the entire model. The Conv2d layers get\n",
        "    progressively larger (more filters) as the model gets deeper. This\n",
        "    corresponds to spatial resolution getting smaller (via the stride=2 blocks),\n",
        "    going from 32x32 -> 16x16 -> 8x8. The nn.AdaptiveAvgPool2d layer at the end\n",
        "    of the model reduces the spatial resolution from 8x8 to 1x1 using a simple\n",
        "    average across all the pixels in each channel. This is then fed to the\n",
        "    single fully connected (linear) layer called classifier, which is the output\n",
        "    prediction of the model.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(3, 32),\n",
        "            conv_block(32, 32),\n",
        "            conv_block(32, 64, stride=2),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 64),\n",
        "            conv_block(64, 128, stride=2),\n",
        "            conv_block(128, 128),\n",
        "            conv_block(128, 256),\n",
        "            conv_block(256, 256),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "            )\n",
        "\n",
        "        self.classifier = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        The forward function is called automatically by the model when it is\n",
        "        given an input image. It first applies the 8 convolution layers, then\n",
        "        finally the single classifier layer.\n",
        "        '''\n",
        "        h = self.model(x)\n",
        "        B, C, _, _ = h.shape\n",
        "        h = h.view(B, C)\n",
        "        return self.classifier(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iNceGsSDzHA"
      },
      "source": [
        "---\n",
        "\n",
        "### **Post-training Quantization**\n",
        "\n",
        "---\n",
        "\n",
        "In this section, I performed post-training quantization of weights on a multi-layer perceptron with fully connected layers to reduce its memory requirements.\n",
        "I started by training a small neural network on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. Then, I quantized its weights and verified that performance does not degrade significantly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHoj5ReoErRy",
        "outputId": "1a58a80a-3812-4cb3-f1b6-890073f2bc3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self, hidden=128):\n",
        "      super(MNISTNet, self).__init__()\n",
        "\n",
        "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
        "      # outputting 32 convolutional features, with a square kernel size of 3\n",
        "      self.hidden = hidden\n",
        "      self.fc1 = nn.Linear(28*28*1, self.hidden)\n",
        "      self.fc2 = nn.Linear(self.hidden, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 28*28)\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train_mnist(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10000 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test_mnist(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "model = MNISTNet()\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "dataset1_mnist = datasets.MNIST('./data_mnist', train=True, download=True,\n",
        "                    transform=transform)\n",
        "dataset2_mnist = datasets.MNIST('./data_mnist', train=False,\n",
        "                    transform=transform)\n",
        "train_loader_mnist = torch.utils.data.DataLoader(dataset1_mnist)\n",
        "test_loader_mnist = torch.utils.data.DataLoader(dataset2_mnist)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=.1)\n",
        "for epoch in range(1, 5):\n",
        "    train_mnist(model, device, train_loader_mnist, optimizer, epoch)\n",
        "    test_mnist(model, device, test_loader_mnist)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:05<00:00, 1894068.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data_mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 345592.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3195576.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10811877.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data_mnist/MNIST/raw\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.133334\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.000006\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.000001\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.000435\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.000013\n",
            "\n",
            "Test set: Average loss: 0.3227, Accuracy: 9252/10000 (93%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000345\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.000008\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.1307, Accuracy: 9702/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001012\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.1223, Accuracy: 9711/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001331\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.000001\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.1219, Accuracy: 9710/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbcPLUGvlVEf"
      },
      "source": [
        "---\n",
        "We will perform post-training quantization on the weights of a neural network. Quantization maps high-precision values to low-precision values to reduce the number of bits used to store each value. In this section we will implement two functions:\n",
        "* **quantize**: compresses a vector/matrix from 32-bit float to 8-bit integer\n",
        "* **dequantize**: takes the output of **quantize** and recovers the original values (possibly with some error).\n",
        "\n",
        "**Quantization Example**\n",
        "\n",
        "Given a vector of 32-bit floats containing the values `[400, 500, 600]`, our goal is to quantize these values so that they are representable in 8 bits. With 8 bits, we can only represent the values 0 through 255 -- but we have a problem: 400, 500 and 600 are outside of this range! To solve this, we want to map the values of the vector such that each value is *approximately* representable by values between 0 and 255. To do this we:\n",
        "1. Shift the vector so that the minimum value is 0\n",
        "2. Scale the vector so that every value is between 0 and 255\n",
        "3. Cast each value to an (8-bit) integer\n",
        "\n",
        "For example, suppose we are quantizing `v=[400,500,600]`.\n",
        "* After shifting would have `shift=400`, `v_shifted=[0,100,200]`.\n",
        "* After scaling, we would have `scale=255/200`, `shift=400`, `v_shifted_scaled=[0*255/200, 100 *255/200, 200 *255/200] = [0, 127.5, 255]`, giving us `v_q=[0, 128, 255]` after rounding.\n",
        "\n",
        "With this process we have successfully quantized the elements of `v` to be representable by 8 bits (with additional `scale` and shift `parameters`). This yields ~4x reduction in size for large vectors!\n",
        "\n",
        "**Dequantization Example**\n",
        "\n",
        "To dequantize, we do the opposite:\n",
        "* Given: `v_q=[0,128,255]`, `shift=400`, `scale=255/200`\n",
        "* Reverse scale: `v_unscaled = v_q / scale = [0, 100.392, 200]`\n",
        "* Reverse shift: `v_unscaled + 400 = [400, 500.392, 600]`\n",
        "\n",
        "As you can see, our dequantized values are very close to our original values (`[400,500,600]`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "def quantize(W):\n",
        "    shift = np.min(W)\n",
        "    W_shift = W - shift\n",
        "    scale = np.float32(255 / np.max(W_shift))\n",
        "    W_quantized = np.round(W_shift * scale)\n",
        "    return np.array(W_quantized, dtype=np.uint8), (shift, scale)\n",
        "\n",
        "def dequantize(W, extra_args):\n",
        "    shift, scale = extra_args\n",
        "    W_unscaled = np.array(W, dtype=np.float32) / scale\n",
        "    return W_unscaled + shift"
      ],
      "metadata": {
        "id": "KDdcyVrcPl2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySO8bbl3tJ7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e522c1-2b4b-46ff-a2a2-62ea393365cc"
      },
      "source": [
        "print(\"Baseline Score\")\n",
        "test_mnist(model, device, test_loader_mnist)\n",
        "\n",
        "state_dict = model.state_dict()\n",
        "state_dict_q = {}\n",
        "for key, value in state_dict.items():\n",
        "  quantized, extra_args = quantize(value.numpy())\n",
        "  dequantized = dequantize(quantized, extra_args)\n",
        "  state_dict_q[key] = torch.from_numpy(dequantized)\n",
        "\n",
        "model.load_state_dict(state_dict_q)\n",
        "\n",
        "print(\"Quantized performance\")\n",
        "test_mnist(model, device, test_loader_mnist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Score\n",
            "\n",
            "Test set: Average loss: 0.1217, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "Quantized performance\n",
            "\n",
            "Test set: Average loss: 0.1217, Accuracy: 9714/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}